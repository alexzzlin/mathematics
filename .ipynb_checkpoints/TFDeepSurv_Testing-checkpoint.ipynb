{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TFDeepSurv: Deep Cox proportional risk model and survival analysis implemented by tensorflow.\n",
    "\n",
    "1. Differences from DeepSurv\n",
    "\n",
    "DeepSurv, a package of Deep Cox proportional risk model, is open-source on Github. But our works may shine in:\n",
    "\n",
    "    Evaluating variable importance in deep neural network.\n",
    "    Identifying ties of death time in your survival data, which means different loss function and estimator for survival function (Breslow or Efron approximation).\n",
    "    Providing survival function estimated by three optional algorithm.\n",
    "    Tuning hyperparameters of DNN using scientific method - Bayesian Hyperparameters Optimization.\n",
    "\n",
    "2. Statement\n",
    "\n",
    "The project is based on the research of Breast Cancer. The paper about this project has been submitted to IEEE JBHI. We will update status here once paper published !\n",
    "3. Installation\n",
    "\n",
    "From source\n",
    "Download TFDeepSurv package and install from the directory (Python version : 3.x):\n",
    "\n",
    "git clone https://github.com/liupei101/TFDeepSurv.git\n",
    "cd TFDeepSurv\n",
    "pip install .\n",
    "\n",
    "\n",
    "4. Get it started:\n",
    "4.1 Runing with simulated data\n",
    "4.1.1 import packages and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tfdeepsurv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-430b5172903e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# https://freesoft.dev/program/155655562\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m### import package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtfdeepsurv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdsl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtfdeepsurv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimulatedData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tfdeepsurv'"
     ]
    }
   ],
   "source": [
    "# https://freesoft.dev/program/155655562\n",
    "### import package\n",
    "from tfdeepsurv import dsl\n",
    "from tfdeepsurv.dataset import SimulatedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate simulated data\n",
    "# data configuration: \n",
    "#     hazard ratio = 2000\n",
    "#     number of features = 10\n",
    "#     number of valid features = 2\n",
    "data_generator = SimulatedData(2000, num_var=2, num_features=10)\n",
    "# training dataset: \n",
    "#     number of rows = 2000\n",
    "#     random seed = 1\n",
    "train_data = data_generator.generate_data(2000, seed=1)\n",
    "# test dataset :\n",
    "#     number of rows = 800\n",
    "#     random seed = 1\n",
    "test_data = data_generator.generate_data(800, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.2 Visualize survival status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "\n",
    "### Visualize survival status\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "l_kmf = []\n",
    "# training set\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(train_data['t'], event_observed=train_data['e'], label='Training Set')\n",
    "kmf.survival_function_.plot(ax=ax)\n",
    "l_kmf.append(kmf)\n",
    "# test set\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(test_data['t'], event_observed=test_data['e'], label='Test Set')\n",
    "kmf.survival_function_.plot(ax=ax)\n",
    "l_kmf.append(kmf)\n",
    "\n",
    "# \n",
    "plt.ylim(0, 1.01)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Survival rate\")\n",
    "plt.title(\"Survival Curve\")\n",
    "plt.legend(loc=\"best\", title=\"Dataset\")\n",
    "add_at_risk_counts(*l_kmf, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.3 Initialize your neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 10\n",
    "output_nodes = 1\n",
    "train_X = train_data['x']\n",
    "train_y = {'e': train_data['e'], 't': train_data['t']}\n",
    "# the arguments of dsnn is obtained by Bayesian Hyperparameters Tuning\n",
    "model = dsl.dsnn(\n",
    "    train_X, train_y,\n",
    "    input_nodes, [6, 3], output_nodes, \n",
    "    learning_rate=0.7,\n",
    "    learning_rate_decay=1.0,\n",
    "    activation='relu', \n",
    "    L1_reg=3.4e-5, \n",
    "    L2_reg=8.8e-5, \n",
    "    optimizer='adam',\n",
    "    dropout_keep_prob=1.0\n",
    ")\n",
    "# Get the type of ties (three types)\n",
    "# 'noties', 'breslow' when ties occur or 'efron' when ties occur frequently\n",
    "print(model.get_ties())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.4 Train neural network model\n",
    "\n",
    "You can train dsnn via two optional functions:\n",
    "\n",
    "    Only for training: model.train(). Refer to #section 4.1.4.a\n",
    "    For training model and watch the learning curve: model.learn(). Refer to #section 4.1.4.b\n",
    "\n",
    "4.1.4.a Training via model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot curve of loss and CI on train data\n",
    "model.train(num_epoch=1900, iteration=100,\n",
    "            plot_train_loss=True, plot_train_ci=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.4.b Training via model.learn()\n",
    "\n",
    "NOTE: the function will firstly clean the running state and then train the model from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_data['x']\n",
    "test_y = {'e': test_data['e'], 't': test_data['t']}\n",
    "# Plot learning curves on watch_list\n",
    "watch_list = {\"trainset\": [train_X, train_y], \"testset\": [test_X, test_y]}\n",
    "model.learn(num_epoch=1900, iteration=100, eval_list=watch_list,\n",
    "            plot_ci=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.5 Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_data['x']\n",
    "test_y = {'e': test_data['e'], 't': test_data['t']}\n",
    "print(\"CI on train set: %g\" % model.score(train_X, train_y))\n",
    "print(\"CI on test set: %g\" % model.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.6 Evaluate variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_vip_byweights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.7 Get estimation of survival function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional algo: 'wwe', 'bls' or 'kp', the algorithm for estimating survival function\n",
    "model.survival_function(test_X[0:3], algo=\"wwe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Runing with real-world data\n",
    "\n",
    "The procedure on real-world data is similar with the described on simulated data. One we need to notice is data preparation. This package provides functions for loading standard dataset for traning or testing.\n",
    "4.2.1 load real-world data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "from tfdeepsurv import dsl\n",
    "from tfdeepsurv.utils import load_data\n",
    "\n",
    "# Notice: the object train_X or test_X returned from function load_data is numpy.array.\n",
    "# the object train_y or test_y returned from function load_data is dict like {'e': numpy.array,'t': numpy.array}.\n",
    "\n",
    "# You can load training data and testing data, respectively\n",
    "train_X, train_y = load_data('train.csv', excluded_col=['ID'], surv_col={'e': 'event', 't': 'time'})\n",
    "test_X, test_y = load_data('test.csv', excluded_col=['ID'], surv_col={'e': 'event', 't': 'time'})\n",
    "# Or load full data, then split it into training and testing set (=8:2).\n",
    "train_X, train_y, test_X, test_y = load_data('full_data.csv', excluded_col=['ID'], surv_col={'e': 'event', 't': 'time'}, split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.2 Traning or testing tfdeepsurv model\n",
    "\n",
    "This is the same as doing in simulated data.\n",
    "\n",
    "5. More properties\n",
    "\n",
    "We provide tools for hyperparameters tuning (Bayesian Hyperparameters Optimization) in deep neural network, which is automatic in searching optimal hyperparameters of DNN.\n",
    "\n",
    "For more usage of Bayesian Hyperparameters Optimization, you can refer to here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
