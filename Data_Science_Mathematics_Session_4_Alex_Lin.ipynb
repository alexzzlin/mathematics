{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Mathematics\n",
    "# K-Means Clustering\n",
    "# In-Class Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are an OSINT analyst for the Marine Corps Intelligence Activity.  You’ve collected a significant number of tweets from a particular geographic region of interest, and are interested in developing an algorithm to illuminate differences that may exist within your data set.  You know that some of the tweets are from known military personnel, and you hope to demonstrate that a clustering technique can be used to highlight these differences within the larger data set.  You’ve engineered quantifiable features from your data, which you intend to use to build a supervised clustering algorithm.\n",
    "\n",
    " | User ID | Feature 1 | Feature 2 | Feature 3 | Military (1=YES, 0=NO) |\n",
    " |---------|-----------|-----------|-----------|------------------------|\n",
    " | 1001 | 8 | 22 | 62 | 1 | \n",
    " | 1002 | 15 | 51 | 85 | 0 | \n",
    " | 1003 | 9 | 44 | 121 | 0 | \n",
    " | 1004 | 8 | 51 | 136 | 0 | \n",
    " | 1005 | 8 | 20 | 93 | 1 | \n",
    " | 1006 | 15 | 64 | 124 | 0 | \n",
    " | 1007 | 14 | 56 | 101 | 0 | \n",
    " | 1008 | 5 | 10 | 80 | 1 | \n",
    " | 1009 | 5 | 18 | 73 | 1 | \n",
    " | 1010 | 9 | 26 | 79 | 1 | \n",
    "\n",
    "Let's analyze our data set using the K-means module of Python.  First, import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import our dataset as a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array([[8,22,62],\n",
    "[15,51,85],\n",
    "[9,44,121],\n",
    "[8,51,136],\n",
    "[8,20,93],\n",
    "[15,64,124],\n",
    "[14,56,101],\n",
    "[5,10,80],\n",
    "[5,18,73],\n",
    "[9,26,79]])\n",
    "\n",
    "Military_Yes_No_True = [1, 0, 0, 0, 1, 0, 0, 1, 1, 1]  # Military (1=YES, 0=NO)\n",
    "\n",
    "#data[0,0], data[0,1]\n",
    "#for dat in data: \n",
    "#    print(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the above data set.  You have determined the three features that you believe have the greatest correlation with military status.\n",
    "\n",
    "**Question a.** Write the code for k-means clustering on the above data set using the algorithms in the slides.  Use the coordinates $(10, 20, 80)$ and $(10, 50, 110)$, corresponding to $(Feature\\ 1, Feature\\ 2, Feature\\ 3)$, as your initial “best guess” clusters.  Note that we have not known yet the mapping of given coordinates to the clusters and their respective associated military YES/NO statuses.\n",
    "\n",
    "**K-Means Algorithm**\n",
    " 1. Select number of clusters: K = 2, Given.\n",
    " 2. Select starting points for K centroids: $(10, 20, 80)$ and $(10, 50, 110)$, Given.\n",
    " 3. Iterate: \n",
    " \n",
    "    3.1. Calcualte distance from all points in the set to each centroid. \n",
    "    \n",
    "    3.2. Cluster points based on proximity to their nearest centorid.  \n",
    "    \n",
    "    3.3. Recalculate centroids based on clusters. \n",
    "    \n",
    "    3.4. Continue until convergence (i.e., cluster populations/centroids no longer change) or to within a certain margin of error.\n",
    "    \n",
    "**Answer a.** Our codes will follow the step sequences specified above.  Note that the choice of centroids coordinates for initial \"best guess\" clusters has an effect in the final converged clusters from our k-means algorithm.  The results will be shown at the end of this in-class activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Select number of clusters\n",
    "K = 2   # Two Clusters\n",
    "\n",
    "# 2. Select starting points for K centroids\n",
    "centers = np.array([[10,20,80],[10,50,110]])      # Two Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute Euclidean distance\n",
    "def euclidean_distance(pointA, pointB):\n",
    "    total = 0\n",
    "    for i in range(len(pointA)):\n",
    "        #print(pointA[i],pointB[i])\n",
    "        total += (pointA[i] - pointB[i]) ** 2\n",
    "        \n",
    "    return total ** 0.5  # faster sqrt\n",
    "\n",
    "#euclidean_distance(data[0],centers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1. Calcualte distance from all points in the set to each centroid.\n",
    "# Calculate the Centroids ~ Slide 21)\n",
    "# centroids = np.mean(data, axis=0)\n",
    "\n",
    "def calc_distance(centers, points):\n",
    "    \"\"\" Inputs: list of points and centers\n",
    "        Output: a list of n dimensions where each dimesion is its own list of\n",
    "                center id, data point index, and their computed distance.\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "\n",
    "    for center in range(len(centers)):\n",
    "        for point in range(len(points)):\n",
    "            #distances.append([center,point,np.linalg.norm(points[point]-centers[center])])\n",
    "            distances.append([center,point,euclidean_distance(points[point],centers[center])])\n",
    "    \n",
    "    return distances\n",
    "            \n",
    "# distance = calc_distance(centers, data)\n",
    "# print(distance[0][2],distance[10][2])\n",
    "# distance\n",
    "# List of [center ID, Point ID, Euclidean distance],\n",
    "#      [[0, 0, 18.2208671582886],\n",
    "#      [0, 1, 31.796226191169293], ....]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2. Cluster points based on proximity to their nearest centorid.\n",
    "def calc_closer(centers, distances, points):\n",
    "    clusters_no = len(centers)\n",
    "    new_sets = [[[] for _ in centers[0]] for _ in range(clusters_no)]\n",
    "    clusters = [[] for _ in range(clusters_no)]\n",
    "    #create an intermediate set of centroids: \n",
    "    num_points = len(points)   # 10 data points\n",
    "    for point in range(num_points):\n",
    "        cents_to_points = []\n",
    "        for cent in range(clusters_no):    # 2 centers\n",
    "            cents_to_points.append(distances[cent*num_points+point][2])\n",
    "        #print(cents_to_points)\n",
    "        val, idx = min((val, idx) for (idx, val) in enumerate(cents_to_points))\n",
    "        \n",
    "        clusters[0].append(point)\n",
    "        clusters[1].append(idx)\n",
    "        #print(val, idx)   \n",
    "        for feature in range(len(centers[0])): \n",
    "            new_sets[idx][feature].append(points[point][feature])\n",
    "        #new_sets[idx][1].append(points[1][point])\n",
    "    return new_sets, clusters\n",
    "\n",
    "# new_sets = calc_closer(centers, distance, data)\n",
    "# print(new_sets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3. Recalculate centroids based on clusters. \n",
    "# 3.4. Continue until convergence (i.e., cluster populations/centroids\n",
    "#      no longer change) or to within a certain margin of error.\n",
    "# Inputs: Take two initial guess centers and data points\n",
    "# Outputs: 1.centers - Final estimated centers of two clusters\n",
    "#          2.new_sets - Data Points assigned to each cluster\n",
    "#          3.clusters - a list of cluster tentative label of 0 or 1 (not sure if it maps to Military Status yet)\n",
    "def user_kmeans(centers,points):\n",
    "    for run in range(5):\n",
    "        print(centers[0], centers[1])\n",
    "        new_centers = []\n",
    "        distance = calc_distance(centers, data)\n",
    "        new_sets, clusters = calc_closer(centers, distance, data)\n",
    "        for cent in range(len(centers)):\n",
    "            new_centers.append(np.mean(np.array(new_sets[cent]), axis=1))\n",
    "        #cent1 = np.mean(np.array(new_sets[0]), axis=1)\n",
    "        #cent2 = np.mean(np.array(new_sets[1]), axis=1)\n",
    "        #centers = [cent1, cent2]\n",
    "        centers = new_centers\n",
    "    return centers, new_sets, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 80] [ 10  50 110]\n",
      "[ 7.  19.2 77.4] [ 12.2  53.2 113.4]\n",
      "[ 7.  19.2 77.4] [ 12.2  53.2 113.4]\n",
      "[ 7.  19.2 77.4] [ 12.2  53.2 113.4]\n",
      "[ 7.  19.2 77.4] [ 12.2  53.2 113.4]\n"
     ]
    }
   ],
   "source": [
    "# rint(np.array(data)[0:,0]), print(np.array(data)[0:,1]), print(np.array(data)[0:,2])\n",
    "# Invoke user_kmean routine\n",
    "centers = np.array([[10,20,80],[10,50,110]])      # Two Centers\n",
    "centers, new_sets, clusters = user_kmeans(centers,data)\n",
    "# Determine the sensible mapping of clusters to Military label (YES=1 and NO=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Our current implementation of k-means algorithm only classifies data points into two generic clusters but does not yet have the mechanism to determine the more sensible or logical mapping of these clusters to the true military labels.  Thus, we will add a corrective step to assign label to each cluster such that the accuracy of our k-means classification is maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step is to ensure the alignment of\n",
    "#    index 0 mapping to Military NO and index 1 mapping to Military YES\n",
    "#    among all the lists or information holders used in the k-means algorithm.\n",
    "def adjust_two_clusters(cluster, Military_True, centers, new_sets):\n",
    "    check = []\n",
    "    for i in range(len(Military_True)):\n",
    "        check.append(cluster[i]==Military_True[i])\n",
    "        \n",
    "    if sum(check) < (len(Military_True) // K):\n",
    "        for i in range(len(Military_True)):\n",
    "            cluster[i] = (cluster[i]+1) % K\n",
    "        centers = [centers[1],centers[0]]\n",
    "        new_sets = [new_sets[1],new_sets[0]]\n",
    "\n",
    "    #print(cluster)\n",
    "    return cluster, centers, new_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the adjusted clusters 0-1 labels are more in line with the values in Military_Yes_No status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prelimiary   Centers: [array([ 7. , 19.2, 77.4]), array([ 12.2,  53.2, 113.4])]\n",
      "            Clusters: [0, 1, 1, 1, 0, 1, 1, 0, 0, 0]\n",
      "         New Sets[0]: [[8, 8, 5, 5, 9], [22, 20, 10, 18, 26], [62, 93, 80, 73, 79]]\n",
      "         New Sets[1]: [[15, 9, 8, 15, 14], [51, 44, 51, 64, 56], [85, 121, 136, 124, 101]]\n",
      "\n",
      "Military Yes/No Flag: [1, 0, 0, 0, 1, 0, 0, 1, 1, 1]\n",
      "\n",
      "Adjusted    Clusters: [1, 0, 0, 0, 1, 0, 0, 1, 1, 1]\n",
      "             Centers: [array([ 12.2,  53.2, 113.4]), array([ 7. , 19.2, 77.4])]\n",
      "         New Sets[0]: [[15, 9, 8, 15, 14], [51, 44, 51, 64, 56], [85, 121, 136, 124, 101]]\n",
      "         New Sets[1]: [[8, 8, 5, 5, 9], [22, 20, 10, 18, 26], [62, 93, 80, 73, 79]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prelimiary   Centers:\", centers)\n",
    "print(\"            Clusters:\", clusters[1])\n",
    "print(\"         New Sets[0]:\", new_sets[0])\n",
    "print(\"         New Sets[1]:\", new_sets[1])\n",
    "clusters[1], centers, new_sets = adjust_two_clusters(clusters[1],Military_Yes_No_True, centers, new_sets)\n",
    "print(\"\")\n",
    "print(\"Military Yes/No Flag:\", Military_Yes_No_True)\n",
    "print(\"\")\n",
    "print(\"Adjusted    Clusters:\", clusters[1])\n",
    "print(\"             Centers:\", centers)\n",
    "print(\"         New Sets[0]:\", new_sets[0])\n",
    "print(\"         New Sets[1]:\", new_sets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question b.** Determine if convergence occurred after two, five iterations of k-means.\n",
    "\n",
    "**Answer b.** Yes, our k-means algorithm converges to the centroids of two clusters at the second iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question c.** How well did your algorithm cluster military personnel versus non-military personnel?  Construct a confusion matrix, and calculate the Matthews’ Correlation Coefficient (write the code vs using numpy---feel free to check with numpy).\n",
    "\n",
    "The Matthews correlation coefficient (MCC) is used in machine learning as a measure of the quality of binary and multiclass classifications. It takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes. The MCC is in essence a correlation coefficient value between $-1$ and $+1$. A coefficient of $+1$ represents a perfect prediction, $0$ an average random prediction and $-1$ an inverse prediction. The statistic is also known as the $\\phi$ coefficient. MCC can be computed for Binary and multiclass labels, but only in the binary case does this relate to information about true and false positives and negatives. [source: Wikipedia]\n",
    "\n",
    "**Answer c.** I used python package sklearn.metrics to construct its confusion matrix and calculated its Matthews’ Correlation Coefficient.  As the result shown below, the value of MCC is $1.0$, representing a perfect prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 0, 0, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "Military_pred = clusters[1]\n",
    "print(Military_pred)\n",
    "matthews_corrcoef(Military_Yes_No_True, Military_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question d.** You selected three features to use in this computation because you determined that they are the three most correlated features with “military” status.  While adding additional features up to a certain point will enhance clustering model accuracy, adding too many features diminishes accuracy.  Explain why this is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer d.** This phenomenon is coined as \"Curse of Dimensionality\", substantiated in both theoretical and practical world.  In the theoretical world, as illustrated in class slide that the distance ($x$) between the center (centroid) the hypercube corners (data points) become unbounded in hyper-dimensional space, thus nearly all of the space occupied by the data points are \"**far away**\" ($x = r \\sqrt{n} \\rightarrow \\infty$ as $n \\rightarrow \\infty$) from any centroid. Unfortunately, this phenomenon of \"Curse of Dimensionality\" is in general true for many machine learning problems, not just for k-means of K-Nearest neighborhood methods.  The class slide also gives a good example - when a measure such as Eclidean distance is defined using many dimensions, there is little difference in the distances between different pairs of samples to the centroids.\n",
    "\n",
    "In practical world, as the Georgia Tech video on \"Curse of Dimensionality\" for machine learning stated that data coverage  is necessary to do learning in order to generalize accurately via a distance or similarity function to the entire space spanned by the additional features. Oftentimes, even in the era of big data, data sparcity problems in the hyper-dimensional space gravely worsens as more and more features get added. Thus adding too many features confuse the learning algorithm and diminishes its accuracy.\n",
    "\n",
    "Additionaly, oftentimes there may exist some correlation among features. As shown in the scatter charts below among the three features, it looks like there exist some degree of linear correlation among these three features: Feature 1 and 2, Feature 1 and 3, and Feature 2 and 3.  These linear relationships indicate that we may be able to model this problem with  reduced features with principal component analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instantiate our k-means object, trained on our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.04, 0.5, 'Feature 2 & Feature 3')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reference: https://matplotlib.org/devdocs/gallery/subplots_axes_and_figures/subplots_demo.html\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(nrows=1,ncols=2,sharex=True, sharey=True, figsize=(6, 6))\n",
    "fig.suptitle('Scatter Plot of Feature 1 vs. Feature 2 and 3')\n",
    "\n",
    "axs[0].scatter(np.array(data)[0:,0], np.array(data)[0:,1])\n",
    "axs[1].scatter(np.array(data)[0:,1], np.array(data)[0:,2])\n",
    "\n",
    "fig.text(0.5, 0.04, 'Feature 1', ha='center')\n",
    "fig.text(0.04, 0.5, 'Feature 2 & Feature 3' , va='center', rotation='vertical')\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Feature 3')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEjCAYAAADdZh27AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAeIUlEQVR4nO3de5hcVZnv8e+PJkBzbSAN0oEQLjHKRRNs8YLjIKCNyiWD4sQZH4PDMTNz8HbUjGS8oDMy4ETP4xnncc7JESYoAhMxBkZH25wg4qjIdAyaALag3NKJJIjNtcUkvOePvWqn0lR3V3e6andV/T7PU0/vvfZlvbu6e7+119q1tiICMzMzgD2KDsDMzKYOJwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4LVhKRPSrq2TnWdJuleSU9Jml+POs2alZNCwSS9RtKPJD0u6TFJP5T08t3c50WS/nNY2XJJn969aJ9Xz3JJf0gn48ckrZb0ogns5wFJZ+1GKH8H/HNE7B8Rq0bY/1CKs/Tq2o36JiPm8da3UNJaSU9I2ijpHyXtWa/6UwzN8D4ukNSf/t+2SLpG0oH1qr8ROCkUKP0xfhP4AnAIMAP4FPBskXFVMsoJ6B8jYn/gSGALsLxuQe10NHDXGOucm5JG6bWpHoGNZAIn9H2BDwDTgVcAZwIfnuy4qtDo7+MPgdMi4iDgWGBPYFI/LDW8iPCroBfQDQyOsc67gXuAJ4G7gVNS+aXAr8rK/ySVvxj4PbADeAoYBBYB24A/pLJ/T+t2AV8HtgL3A+8rq/eTwI3AtcATwH+rENty4NNl828Gnirb/tqyZeeRnbgHgVuBF6fyrwDPAUMptr8Z5X24D3gMuBnoSuW/Grb93hW2fQA4q0L5QcBVwGZggOzk0JaWHQfcAvwWeBT4KtAxUszA6cDGkeqt9H6OVn8VfzsfLP0eKyz738Bnh5XdBHwwTX8k1fck0A+cWWWdTfU+AvsDXwb+o+hzwVR6FR5AK7+AA9M/yzXAG4GDhy2/MP2RvxwQcDxwdNmyLrKrvT8FngaOSMsuAv5z2L6Ws+sJfA9gLfAJYC+yT02/BnrS8k+SJZL5ad32CvHn+0z/YNcBPyjb/to0/cIU3+uBaemf/z5gr7S84smmrJ4z0gnlFGBvsiur28qWj7X9SCezVcD/AfYDDgPuAP4yLTs+xbs30AncBnx+pH1WeTLb5f0crf4q/nZWAVeOsOy1wMOA0vzBZCfeLmBOWlZKqrOA46qssyneR+A1wONAkP1dvqHoc8FUehUeQKu/yD7ZLwc2AtvJPgUfnpb1Au+vcj93Auen6YsYOym8Anho2DpLgH9N05+k7MQ7Qp3Lya5KBoHfpNiPK9u+lBQ+Dqwo224PsmR3epqveLIpW/8qsmaq0vz+6cQwq8rtH2DnVdNgOokcTtZM11623tuB742wj/nAumH7HO/JrDyRjav+Yft9V/p7mT7CcgEPAa9N8+8GbknTx5M1850FTBvn32qzvY8z0v5eOJ73odlfde2osueLiHvITuKkTtprgc+T/WEfRdY88jyS3knWhDArFe1P1t5craOBLkmDZWVtwA/K5h+uYj+fjYiPjbFOF/BgaSYinpP0MNk/ZTW6gJ+Wbf+UpN+m7R+och/zI+L/lWYknUp21bJZUql4D9IxSzoM+Cfgj4AD0rLfVVnXSMrfz6NHq38k6e6qK8lOko9WWiciQtINZH9DtwF/RvZ3RUTcJ+kDZCfDEyX1kjUrVds30BTvI0BEDEj6DnAD2VWo4Y7mKSUifkH26fukVPQwWZvsLiQdDfxf4D3AoRHRAWwg+4QI2WXx83Y/bP5h4P6I6Ch7HRARbxplm4naRPbPW4pfZAlvoMp6hm+/H3Bo2fYT8TDZJ8zpZcd/YEScmJZfkeJ6SUQcCLyDne9vpZifJusMLsXYRtZcUq58m7Hqfx5JZ5P93s+NiPVjHN/1wFvT38oryPqOsiAirouI15C9pwF8Zox9jabh3sdh9qTC/1grc1IokKQXSfqQpCPT/FFkn+5uT6t8CfiwpJcpc3z6J9+P7B9ja9ruXexMJACPAEdK2mtY2bFl83cAT0j6iKR2SW2STtrd22FHsAJ4s6QzJU0DPkT2j/yjEWIb7jrgXZLmStob+AfgJxHxwEQDiojNwHeBz0k6UNIeko6T9MdplQNITSWSZgCLh+1ieMy/BPaR9OZ0jB8ja0efaP27kHQGWSftWyLijiqObx3Z38eXgN6IGEz7mSPpjPQ+/p6sr2HHWPvbjeOYau/jn0uamf6fjgYuB9aM/8ibl5NCsZ4k+xT3E0lPkyWDDWQnTSLia2R/tNeldVcBh0TE3cDngB+T/VOdTHarXcktZHf6/EZSqYnhKuAESYOSVkXEDuBcYC7ZnUePkp1ADprsg4yIfrJPiF9I9ZxL9mn3D2mVK4CPpdied5tlRKwh65f4OtkdJscBCyYhtHeSdbLfTdakcSNwRFr2KbImhceBbwErh227S8wR8Tjw38newwGyT7wbd6P+4T5O9rv5j7LvCHx7jP1fT9Z3cF1Z2d5kzU+PkvUDHQb8LeQnzLFu7R3vcUy19/EEsg8jT5H9z/ST9blYUro7wczMzFcKZma2k5OCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7PcnkUHsDumT58es2bNKjoMM7OGsnbt2kcjorPSsoZOCrNmzaKvr6/oMMzMGoqkB0da5uYjMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOzXEPffWRmzWXVugGW9vazaXCIro52FvfMYf68GUWH1VKcFMxsSli1boAlK9cztG0HAAODQyxZuR7AiaGO3HxkZlPC0t7+PCGUDG3bwdLe/oIiak1OCmY2JWwaHBpXudWGk4KZTQldHe3jKrfacFIwsylhcc8c2qe17VLWPq2NxT1zCoqoNbmj2cymhFJnsu8+KpaTgplNGfPnzXASKJibj8zMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlapYUJF0taYukDWVlfy/p55LulPRdSV1ly5ZIuk9Sv6SeWsVlZmYjq+WVwnLg7GFlSyPiJRExF/gm8AkASScAC4AT0zZflNSGmZnVVc2SQkTcBjw2rOyJstn9gEjT5wM3RMSzEXE/cB9waq1iMzOzyuo+9pGky4F3Ao8Dr0vFM4Dby1bbmMoqbb8IWAQwc+bM2gVqZtaC6t7RHBEfjYijgK8C70nFqrTqCNsvi4juiOju7OysVZhmZi2pyLuPrgPekqY3AkeVLTsS2FT3iMzMWlxdk4Kk2WWz5wG/SNM3Awsk7S3pGGA2cEc9YzMzsxr2KUi6HjgdmC5pI3AZ8CZJc4DngAeBvwKIiLskrQDuBrYDl0TEjoo7NjOzmlFExab7htDd3R19fX1Fh2Fm1lAkrY2I7krL/I1mMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCxX9wHxzMxs4latG2Bpbz+bBofo6mhncc8c5s+rOH7ohDgpmJk1iFXrBliycj1D27IBHwYGh1iycj3ApCUGNx+ZmTWIpb39eUIoGdq2g6W9/ZNWh5OCmVmD2DQ4NK7yiXBSMDNrEF0d7eMqnwgnBTOzBrG4Zw7t03Z9fH37tDYW98yZtDrc0Wxm1iBKncm++8jMzIAsMUxmEhjOScGshdT6HndrfE4KZi2iHve4W+NzR7NZi6jHPe7W+GqWFCRdLWmLpA1lZUsl/ULSzyV9Q1JH2bIlku6T1C+pp1ZxmbWqetzjbo2vllcKy4Gzh5WtBk6KiJcAvwSWAEg6AVgAnJi2+aKkNsxs0tTjHndrfDVLChFxG/DYsLLvRsT2NHs7cGSaPh+4ISKejYj7gfuAU2sVm1krqsc97tb4iuxT+Avg22l6BvBw2bKNqex5JC2S1Cepb+vWrTUO0ax5zJ83gysuOJkZHe0ImNHRzhUXnOxOZttFIXcfSfoosB34aqmowmpRaduIWAYsA+ju7q64jplVVut73K3x1T0pSFoInAOcGRGlk/pG4Kiy1Y4ENtU7NjOzVlfX5iNJZwMfAc6LiGfKFt0MLJC0t6RjgNnAHfWMzczManilIOl64HRguqSNwGVkdxvtDayWBHB7RPxVRNwlaQVwN1mz0iURsaPyns3MrFa0swWn8XR3d0dfX1/RYZiZNRRJayOiu9Iyf6PZzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHI1SwqSrpa0RdKGsrILJd0l6TlJ3cPWXyLpPkn9knpqFZeZmY2sllcKy4Gzh5VtAC4AbisvlHQCsAA4MW3zRUltNYzNzMwqqFlSiIjbgMeGld0TEf0VVj8fuCEino2I+4H7gFNrFZuZmVU2VfoUZgAPl81vTGVmZlZHUyUpqEJZVFxRWiSpT1Lf1q1baxyWmVlrmSpJYSNwVNn8kcCmSitGxLKI6I6I7s7OzroEZ2bWKqZKUrgZWCBpb0nHALOBOwqOycys5exZqx1Luh44HZguaSNwGVnH8xeATuBbku6MiJ6IuEvSCuBuYDtwSUTsqFVsZmZWWc2SQkS8fYRF3xhh/cuBy2sVj5mZjW2qNB+ZmdkU4KRgZma5UZOCpBdIekGa7pR0gaQT6xOamZnV24hJQdJfAj8Gbpf018A3gXOAlZIurlN8ZmZWR6N1NL+HbCyiduBB4PiI+I2kg4HvAVfVIT4zM6uj0ZLCtoh4BnhG0q8i4jcAEfE7SRW/bWxmZo1ttD6F5yRNS9NvLhVK2meM7czMrEGNdnK/gDT+UERsLCs/FPhQLYMyM7NijNh8FBEPjVA+AAzULCIzMyuMm4HMzCznpGBmZrmqkoKkdklzah2MmZkVa8ykIOlc4E7gO2l+rqSbax2YmZnVXzVXCp8ke17yIEBE3AnMql1IZmZWlGqSwvaIeLzmkZiZWeGqeZ7CBkl/BrRJmg28D/hRbcMyM7MiVJMU3gt8FHgWuA7oBT5dy6DMzOph1boBlvb2s2lwiK6Odhb3zGH+vBlFh1WoUZOCpDbg5og4iywxmJk1hVXrBliycj1D27In/w4MDrFk5XqAlk4Mo/YppOckPyPpoPHuWNLVkrZI2lBWdoik1ZLuTT8PLlu2RNJ9kvol9Yy3PjOz8Vja258nhJKhbTtY2ttfUERTQzUdzb8H1ku6StI/lV5VbLccOHtY2aXAmoiYDaxJ80g6AVhANlT32cAX01WKmVlNbBocGld5q6imT+Fb6TUuEXGbpFnDis8HTk/T1wC3Ah9J5TdExLPA/ZLuI7sN9sfjrdfMrBpdHe0MVEgAXR3tBUQzdYyZFCLimkms7/CI2Jz2u1nSYal8BnB72XobU9nzSFoELAKYOXPmJIZmZq1kcc+cXfoUANqntbG4p7UHbxgzKUi6nzSEdrmIOHYS41CFsooP8omIZcAygO7ubj/sx8wmpNSZ7LuPdlVN81F32fQ+wIXAIROs7xFJR6SrhCOALal8I3BU2XpHApsmWIeZWVXmz5vR8klguDE7miPit2WvgYj4PHDGBOu7GViYphcCN5WVL5C0t6RjgNnAHROsw8zMJqia5qNTymb3ILtyOKCK7a4n61SeLmkjcBlwJbBC0sXAQ2RXHUTEXZJWAHcD24FL0u2wZmZWR9U0H32ubHo7cD/wtrE2ioi3j7DozBHWvxy4vIp4zMysRqpJChdHxK/LC1ITj5mZNZlqvrx2Y5VlZmbW4Ea8UpD0IrJvGB8k6YKyRQeS3YVkZmZNZrTmoznAOUAHcG5Z+ZPAu2sZlJmZFWPEpBARNwE3SXpVRHi4CTOzFlBNR/M6SZeQNSXlzUYR8Rc1i8rMzApRTUfzV4AXAD3A98m+bfxkLYMyM7NiVJMUjo+IjwNPp8Hx3gycXNuwzMysCNUkhW3p56Ckk4CDgFk1i8jMzApTTZ/CsvSEtI+TjVG0P/CJmkZlZmaFqOZ5Cl9Kk98HJnO4bKsRP4zczCZqzOYjSYenR3F+O82fkAa0symo9DDygcEhgp0PI1+1bqDo0MysAVTTp7Ac6AW60vwvgQ/UKiDbPX4YuZntjmqSwvSIWAE8BxAR2wEPaz1F+WHkZrY7qkkKT0s6lPR4TEmvBB6vaVQ2YSM9dLzVH0ZuZtWpJil8kOyuo+Mk/RD4MvDemkZlE7a4Zw7t09p2KfPDyM2sWqONkjozIh6KiJ9K+mOyAfIE9EfEtpG2s2L5YeRmtjtGuyV1FVB6FOe/RcRb6hCPTQI/jNzMJmq05iOVTU/q9xMkvV/SBkl3SfpAKjtE0mpJ96afB09mnWZmNrbRkkKMML1b0lAZ7wZOBV4KnCNpNnApsCYiZgNr0ryZmdXRaM1HL5X0BNkVQ3uaJs1HRBw4wTpfDNweEc8ASPo+8CfA+cDpaZ1rgFuBj0ywDjMzm4DRHrLTNtKy3bQBuDzd5joEvAnoAw6PiM2p7s2SDqu0saRFwCKAmTNn1ihEM7PWVM0tqZMqIu4BPgOsBr4D/AzYPo7tl0VEd0R0d3Z21ihKM7PWVPekABARV0XEKRHxWuAx4F7gEUlHAKSfW4qIzcyslRWSFEpNQ5JmAhcA15N9QW5hWmUhcFMRsZmZtbJqnqdQC19PfQrbgEsi4neSrgRWpBFYHwIuLCg2M7OWVUhSiIg/qlD2W+DMAsIxM7OkkOYjMzObmpwUzMws56RgZmY5JwUzM8sVdfeRmdnzrFo34GHfC+akYGZTwqp1AyxZuT5/xvjA4BBLVq4HcGKoIzcfmdmUsLS3P08IJUPbdrC0t7+giFqTk4KZTQmbBofGVW614aRgZlNCV0f7uMqtNpwUzGxKWNwzh/Zpu47Y3z6tjcU9cwqKqDW5o9nMpoRSZ7LvPiqWk4KZTRnz581wEiiYm4/MzCznpGBmZjknBTMzyzkpmJlZzknBzMxyRT2j+X9IukvSBknXS9pH0iGSVku6N/08uIjYzMxaWd2TgqQZwPuA7og4CWgDFgCXAmsiYjawJs3XxKp1A5x25S0cc+m3OO3KW1i1bqBWVZmZNZSimo/2BNol7QnsC2wCzgeuScuvAebXouLSSIwDg0MEO0didGIwMysgKUTEAPBZ4CFgM/B4RHwXODwiNqd1NgOH1aJ+j8RoZjayun+jOfUVnA8cAwwCX5P0jnFsvwhYBDBz5sxx1++RGOvHD0wxazxFNB+dBdwfEVsjYhuwEng18IikIwDSzy2VNo6IZRHRHRHdnZ2d467cIzHWh5vpzBpTEUnhIeCVkvaVJOBM4B7gZmBhWmchcFMtKvdIjPXhZjqzxlT35qOI+ImkG4GfAtuBdcAyYH9ghaSLyRLHhbWo3yMx1oeb6cwaUyGjpEbEZcBlw4qfJbtqqDmPxFh7XR3tDFRIAG6mM5va/I1mqwk305k1Jj9PwWrCzXRmjclJwWrGzXRmjcfNR2ZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxy/vJag/CzCcysHpwUGkDp2QSloahLzyYAnBjMbFK5+agB+NkEZlYvTgoNwM8mMLN6cVJoAH6EqJnVi5NCA/CzCcysXtzR3AD8bAIzq5e6JwVJc4B/Kys6FvgE8OVUPgt4AHhbRPyu3vFNVX42gZnVQ92bjyKiPyLmRsRc4GXAM8A3gEuBNRExG1iT5s3MrI6K7lM4E/hVRDwInA9ck8qvAeYXFpWZWYsqOiksAK5P04dHxGaA9POwwqIyM2tRhSUFSXsB5wFfG+d2iyT1SerbunVrbYIzM2tRRV4pvBH4aUQ8kuYfkXQEQPq5pdJGEbEsIrojoruzs7NOoZqZtYYik8Lb2dl0BHAzsDBNLwRuqntEZmYtrpCkIGlf4PXAyrLiK4HXS7o3LbuyiNjMzFpZIV9ei4hngEOHlf2W7G4kMzMrSNF3H5mZ2RTipGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMcoWMkmpTx6p1Ayzt7WfT4BBdHe0s7pnD/Hkzig7LzAripNDCVq0bYMnK9Qxt2wHAwOAQS1auB3BiMGtRbj5qYUt7+/OEUDK0bQdLe/sLisjMiuak0MI2DQ6Nq9zMmp+TQgvr6mgfV7mZNb+intHcIelGSb+QdI+kV0k6RNJqSfemnwcXEVsrWdwzh/ZpbbuUtU9rY3HPnIIiMrOiFXWl8L+A70TEi4CXAvcAlwJrImI2sCbNWw3NnzeDKy44mRkd7QiY0dHOFRec7E5msxamiKhvhdKBwM+AY6Osckn9wOkRsVnSEcCtETHqR9bu7u7o6+urbcBmZk1G0tqI6K60rIgrhWOBrcC/Slon6UuS9gMOj4jNAOnnYZU2lrRIUp+kvq1bt9YvajOzFlBEUtgTOAX4l4iYBzzNOJqKImJZRHRHRHdnZ2etYjQza0lFJIWNwMaI+Emav5EsSTySmo1IP7cUEJuZWUure1KIiN8AD0sq9RecCdwN3AwsTGULgZvqHZuZWasrapiL9wJflbQX8GvgXWQJaoWki4GHgAsLis3MrGXV/e6jySRpK/DgbuxiOvDoJIUzFfn4Gl+zH6OPrxhHR0TFTtmGTgq7S1LfSLdlNQMfX+Nr9mP08U09HubCzMxyTgpmZpZr9aSwrOgAaszH1/ia/Rh9fFNMS/cpmJnZrlr9SsHMzMq0RFKQdLWkLZI2lJU1zVDdko6S9L00DPldkt6fypvpGPeRdIekn6Vj/FQqb5pjBJDUlsYE+2aab5rjk/SApPWS7pTUl8qa5vigOR4L0BJJAVgOnD2srJmG6t4OfCgiXgy8ErhE0gk01zE+C5wRES8F5gJnS3olzXWMAO8nG0q+pNmO73URMbfsNs1mO77GfyxARLTEC5gFbCib7weOSNNHAP1FxziJx3oT8PpmPUZgX+CnwCua6RiBI8lOGmcA30xlzXR8DwDTh5U10/EdCNxP6qtt1GNslSuFSqoaqrvRSJoFzAN+QpMdY2pauZNssMTVkQ2q2EzH+Hngb4Dnysqa6fgC+K6ktZIWpbJmOr7deizAVNHKSaHpSNof+DrwgYh4ouh4JltE7IiIuWSfqE+VdFLRMU0WSecAWyJibdGx1NBpEXEK8EayJs7XFh3QJNutxwJMFa2cFJpqqG5J08gSwlcjYmUqbqpjLImIQeBWsn6iZjnG04DzJD0A3ACcIelamuf4iIhN6ecW4BvAqTTR8dEkjwVo5aTQNEN1SxJwFXBPRPzPskXNdIydkjrSdDtwFvALmuQYI2JJRBwZEbOABcAtEfEOmuT4JO0n6YDSNPAGYANNcnzQPI8FaIkvr0m6HjidbMTCR4DLgFXACmAmaajuiHisqBh3h6TXAD8A1rOzPfpvyfoVmuUYXwJcA7SRhlmPiL+TdChNcowlkk4HPhwR5zTL8Uk6luzqALJmlusi4vJmOb4SSXOBLwHPeywADXKMLZEUzMysOq3cfGRmZsM4KZiZWc5JwczMck4KZmaWc1IwM7Ock4K1NEk70qidpdesCexjfhqAcNJJmivpx2lk2J9L+tNa1GNW4ltSraVJeioi9t/NfSwnG8DuxnFss2dEbK9ivRcCERH3SuoC1gIvTt/qNpt0vlIwG0bSyyR9Pw3c1ls2RMG7Jf1XeqbD1yXtK+nVwHnA0nSlcZykWyV1p22mp6ErkHSRpK9J+neygeH2U/asj/9KA6idPzyWiPhlRNybpjeRDZHQWZ93wlqRk4K1uvaypqNvpDGkvgC8NSJeBlwNXJ7WXRkRL4/smQ73ABdHxI/IhjFYHNlzAn41Rn2vAhZGxBnAR8mGs3g58DqyxLLfSBtKOpXsm7Jj1WE2YXsWHYBZwYbSyKsApJFXTwJWZ0NK0QZsTotPkvRpoAPYH+idQH2ry4Y4eAPZIHgfTvP7kA2FcM/wjdLVylfIEspzw5ebTRYnBbNdCbgrIl5VYdlyYH5E/EzSRWTjaVWynZ1X4fsMW/b0sLreEhH9owYkHQh8C/hYRNw+avRmu8nNR2a76gc6Jb0KsiHJJZ2Ylh0AbE5NTH9ets2TaVnJA8DL0vRbR6mrF3hvGuUWSfOGryBpL7KB5L4cEV8b/+GYjY+TglmZiPgD2Yn8M5J+BtwJvDot/jjZyLOryYbtLrkBWJw6i48DPgv8taQfkY3MO5K/B6YBP5e0Ic0P9zbgtcBFZX0fcyusZzYpfEuqmZnlfKVgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLPf/AQUsjy9Gx/ekAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.array(data)[0:,1], np.array(data)[0:,2])\n",
    "plt.suptitle('Scatter Plot of Feature 2 vs. Feature 3')\n",
    "plt.xlabel('Feature 2')\n",
    "plt.ylabel('Feature 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the \"labels\" method to get our data labels.  Each different integer represents a different cluster.  Note that its MCC is 0.816."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Military_Yes_No_True =  [1 0 0 0 1 0 0 1 1 1]\n",
      "Military_pred_kmeans =  [1 1 0 0 1 0 0 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.816496580927726"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Military_pred_kmeans = kmeans.labels_\n",
    "print(\"Military_Yes_No_True = \", np.array(Military_Yes_No_True))\n",
    "print(\"Military_pred_kmeans = \", Military_pred_kmeans)\n",
    "matthews_corrcoef(Military_Yes_No_True, Military_pred_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the lables make sense based on our input data?  Go back to the in-class activity and see if the labels are the same.  Note that this algorithm may choose a different label convention (i.e., not 1=Military and 0=Non-Military, like in our example).  What we are interested in is the correct pattern in the label sequence.\n",
    "\n",
    "**Response** Yes, the lables make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find our centroids.  Do they match what you calculated where you wrote the code above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.5       ,  53.75      , 120.5       ],\n",
       "       [  8.33333333,  24.5       ,  78.66666667]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 24 78] [ 11  54 120]\n",
      "[ 8.33333333 24.5        78.66666667] [ 11.5   53.75 120.5 ]\n",
      "[ 8.33333333 24.5        78.66666667] [ 11.5   53.75 120.5 ]\n",
      "[ 8.33333333 24.5        78.66666667] [ 11.5   53.75 120.5 ]\n",
      "[ 8.33333333 24.5        78.66666667] [ 11.5   53.75 120.5 ]\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 0, 1, 1, 0, 1, 1, 0, 0, 0]]\n",
      "[array([ 8.33333333, 24.5       , 78.66666667]), array([ 11.5 ,  53.75, 120.5 ])]\n",
      "[[8, 15, 8, 5, 5, 9], [22, 51, 20, 10, 18, 26], [62, 85, 93, 80, 73, 79]]\n",
      "[[9, 8, 15, 14], [44, 51, 64, 56], [121, 136, 124, 101]]\n"
     ]
    }
   ],
   "source": [
    "centers_2 = np.array([[8,24,78],[11,54,120]])      # Two Centers\n",
    "centers_2, new_sets_2, clusters_2 = user_kmeans(centers_2,data)\n",
    "print(clusters_2)\n",
    "print(centers_2)\n",
    "print(new_sets_2[0])\n",
    "print(new_sets_2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 15 10] [10 30 50]\n",
      "[nan nan nan] [ 9.6 36.2 95.4]\n",
      "[ 9.6 36.2 95.4] [nan nan nan]\n",
      "[ 9.6 36.2 95.4] [nan nan nan]\n",
      "[ 9.6 36.2 95.4] [nan nan nan]\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "[array([ 9.6, 36.2, 95.4]), array([nan, nan, nan])]\n",
      "[[8, 15, 9, 8, 8, 15, 14, 5, 5, 9], [22, 51, 44, 51, 20, 64, 56, 10, 18, 26], [62, 85, 121, 136, 93, 124, 101, 80, 73, 79]]\n",
      "[[], [], []]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:153: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "# This choice led to a single cluster\n",
    "centers_3 = np.array([[5,15,10],[10,30,50]])      # Two Centers\n",
    "centers_3, new_sets_3, clusters_3 = user_kmeans(centers_3,data)\n",
    "print(clusters_3)\n",
    "print(centers_3)\n",
    "print(new_sets_3[0])\n",
    "print(new_sets_3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now save your output.  Go to File -> Print Preview and save your final output as a PDF.  Turn in to your Instructor, along with any additional sheets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
